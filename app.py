import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageOps
from streamlit_cropper import st_cropper

# „Éö„Éº„Ç∏Ë®≠ÂÆö
st.set_page_config(
    page_title="Braille Reader",
    page_icon="üîç",
    layout="centered"
)

# ==========================================
# Èñ¢Êï∞: ÁîªÂÉè„ÅÆÂÇæ„ÅçË£úÊ≠£
# ==========================================
def correct_skew(image, contours):
    if not contours:
        return image, 0
    
    all_points = np.concatenate(contours)
    rect = cv2.minAreaRect(all_points)
    angle = rect[-1]
    
    if angle < -45: angle = -(90 + angle)
    else: angle = -angle
        
    if abs(angle) > 10.0: return image, 0
    if abs(angle) < 0.2: return image, 0

    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    
    cos, sin = np.abs(M[0, 0]), np.abs(M[0, 1])
    new_w = int((h * sin) + (w * cos))
    new_h = int((h * cos) + (w * sin))
    M[0, 2] += (new_w / 2) - center[0]
    M[1, 2] += (new_h / 2) - center[1]

    return cv2.warpAffine(image, M, (new_w, new_h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE), angle

# ==========================================
# Èñ¢Êï∞: ÁÇπÂ≠óËß£Êûê„É°„Ç§„É≥„É≠„Ç∏„ÉÉ„ÇØ
# ==========================================
def process_braille_image(image_array):
    # 1. ÂâçÂá¶ÁêÜ
    if len(image_array.shape) == 3:
        gray_image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)
    else:
        gray_image = image_array
        
    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)
    thresh_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)

    # 2. „Éâ„ÉÉ„ÉàÊ§úÂá∫ & ÂÇæ„ÅçË£úÊ≠£
    contours, _ = cv2.findContours(thresh_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    dot_contours = [cnt for cnt in contours if 10 < cv2.contourArea(cnt) < 5000]
    
    corrected_img, angle = correct_skew(gray_image, dot_contours)
    
    # Ë£úÊ≠£ÂæåÂÜçÂá¶ÁêÜ
    blurred_corr = cv2.GaussianBlur(corrected_img, (5, 5), 0)
    thresh_corr = cv2.adaptiveThreshold(blurred_corr, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
    contours_final, _ = cv2.findContours(thresh_corr, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

    # 3. „Éâ„ÉÉ„ÉàÊäΩÂá∫
    raw_dots = []
    radii_list = []
    dot_id_counter = 0

    for contour in contours_final:
        area = cv2.contourArea(contour)
        if 3 < area < 5000: 
            (x, y), radius = cv2.minEnclosingCircle(contour)
            center = (int(x), int(y))
            
            # ÂΩ¢Áä∂„Éï„Ç£„É´„Çø
            x_r, y_r, w_r, h_r = cv2.boundingRect(contour)
            aspect = float(w_r) / h_r
            if aspect > 1.8 or aspect < 0.5: continue

            # ÂÖÖÂ°´Áéá„Éï„Ç£„É´„Çø
            mask = np.zeros(thresh_corr.shape, dtype=np.uint8)
            cv2.circle(mask, center, int(radius), 255, -1)
            mean_val = cv2.mean(thresh_corr, mask=mask)[0]
            if mean_val < 130: continue 

            raw_dots.append({'id': dot_id_counter, 'center': center, 'radius': radius})
            radii_list.append(radius)
            dot_id_counter += 1

    if not raw_dots: return corrected_img, "„Éâ„ÉÉ„Éà„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ", []

    median_radius = np.median(radii_list)
    braille_dots = []
    for dot in raw_dots:
        if median_radius * 0.5 <= dot['radius'] <= median_radius * 2.0:
            braille_dots.append(dot)
    
    if not braille_dots: return corrected_img, "ÊúâÂäπ„Å™„Éâ„ÉÉ„Éà„Å™„Åó", []
    
    avg_radius = np.mean([d['radius'] for d in braille_dots])

    # 4. Ë°å„ÅÆÂàÜÈõ¢
    braille_dots.sort(key=lambda d: d['center'][1])
    lines_of_dots = []
    if braille_dots:
        current_line = [braille_dots[0]]
        current_line_y_sum = braille_dots[0]['center'][1]
        for i in range(1, len(braille_dots)):
            dot = braille_dots[i]
            dy = dot['center'][1]
            avg_y = current_line_y_sum / len(current_line)
            if abs(dy - avg_y) < avg_radius * 3.0: 
                current_line.append(dot)
                current_line_y_sum += dy
            else:
                lines_of_dots.append(current_line)
                current_line = [dot]
                current_line_y_sum = dy
        lines_of_dots.append(current_line)

    braille_cells = []
    used_dot_ids = set()

    # --- Ë°å„Åî„Å®„ÅÆÂá¶ÁêÜ ---
    for line_dots in lines_of_dots:
        if not line_dots: continue
        
        line_center_y = np.median([d['center'][1] for d in line_dots])
        line_dots.sort(key=lambda d: d['center'][0])
        dots_x = np.array([d['center'][0] for d in line_dots])

        x_diffs = np.diff(dots_x)
        gap_threshold = avg_radius * 4.5
        groups = []
        current_group = [line_dots[0]]
        for i, diff in enumerate(x_diffs):
            if diff < gap_threshold:
                current_group.append(line_dots[i+1])
            else:
                groups.append(current_group)
                current_group = [line_dots[i+1]]
        groups.append(current_group)

        # „Ç∞„É™„ÉÉ„ÉâË®àÁÆó
        group_starts = np.array([min([d['center'][0] for d in g]) for g in groups])
        
        estimated_pitch = avg_radius * 6.0
        if len(group_starts) > 1:
            diffs = np.diff(group_starts)
            valid_diffs = diffs[diffs > avg_radius * 4.0]
            if len(valid_diffs) > 0:
                estimated_pitch = np.percentile(valid_diffs, 25)

        base_x = group_starts[0]
        indices = np.round((group_starts - base_x) / estimated_pitch)
        
        # Á∑öÂΩ¢ÂõûÂ∏∞ („Ç®„É©„ÉºÂõûÈÅø‰ªò„Åç)
        PERFECT_PITCH = estimated_pitch
        PERFECT_START = base_x
        
        if len(indices) >= 2:
            try:
                slope, intercept = np.polyfit(indices, group_starts, 1)
                PERFECT_PITCH = slope
                PERFECT_START = intercept
            except:
                pass

        y_dists = [abs(d['center'][1] - line_center_y) for d in line_dots]
        valid_y = [dy for dy in y_dists if dy > avg_radius * 0.5]
        v_pitch = np.median(valid_y) if valid_y else avg_radius * 2.5

        # „Çª„É´ÁîüÊàê
        start_idx = int(min(indices)) if len(indices)>0 else 0
        end_idx = int(max(indices)) if len(indices)>0 else 0
        
        FIXED_W = int(PERFECT_PITCH * 0.75)
        FIXED_H = int(v_pitch * 2 + avg_radius * 3)
        INTRA_PITCH = avg_radius * 2.5

        for idx in range(start_idx, end_idx + 1):
            cell_left = PERFECT_START + (idx * PERFECT_PITCH)
            cell_center_x = cell_left + (PERFECT_PITCH * 0.4) 
            
            t_col1 = cell_center_x - (INTRA_PITCH / 2)
            t_col2 = cell_center_x + (INTRA_PITCH / 2)
            
            t_y1 = line_center_y - v_pitch
            t_y2 = line_center_y
            t_y3 = line_center_y + v_pitch
            
            targets = [
                (t_col1, t_y1), (t_col1, t_y2), (t_col1, t_y3),
                (t_col2, t_y1), (t_col2, t_y2), (t_col2, t_y3)
            ]
            
            pattern = [False] * 6
            has_dot = False
            
            search_x_min = cell_left - (PERFECT_PITCH * 0.1)
            search_x_max = cell_left + (PERFECT_PITCH * 0.9)
            local_dots = [d for d in line_dots if search_x_min < d['center'][0] < search_x_max]
            
            for dot in local_dots:
                if dot['id'] in used_dot_ids: continue
                dx, dy = dot['center']
                min_dist = float('inf')
                best_idx = -1
                for ti, (tx, ty) in enumerate(targets):
                    dist = np.sqrt((dx - tx)**2 + ((dy - ty)*0.8)**2)
                    if dist < min_dist:
                        min_dist = dist
                        best_idx = ti
                
                if min_dist < avg_radius * 3.5:
                    pattern[best_idx] = True
                    has_dot = True
                    used_dot_ids.add(dot['id'])

            anchor_x = int(cell_center_x - (FIXED_W / 2))
            anchor_y = int(line_center_y - (FIXED_H / 2))
            
            braille_cells.append({
                'rect': (anchor_x, anchor_y, FIXED_W, FIXED_H),
                'pattern': pattern,
                'has_dot': has_dot,
                'is_space': not has_dot
            })
            
        braille_cells.append({'is_newline': True})

    # 5. ÁøªË®≥Âá¶ÁêÜ
    def get_dots_tuple(bool_pattern):
        return tuple(i + 1 for i, b in enumerate(bool_pattern) if b)

    jp_map = {
        (1,): "„ÅÇ", (1, 2): "„ÅÑ", (1, 4): "„ÅÜ", (1, 2, 4): "„Åà", (2, 4): "„Åä",
        (1, 6): "„Åã", (1, 2, 6): "„Åç", (1, 4, 6): "„Åè", (1, 2, 4, 6): "„Åë", (2, 4, 6): "„Åì",
        (1, 5, 6): "„Åï", (1, 2, 5, 6): "„Åó", (1, 4, 5, 6): "„Åô", (1, 2, 4, 5, 6): "„Åõ", (2, 4, 5, 6): "„Åù",
        (1, 3, 5): "„Åü", (1, 2, 3, 5): "„Å°", (1, 3, 4, 5): "„Å§", (1, 2, 3, 4, 5): "„Å¶", (2, 3, 4, 5): "„Å®",
        (1, 3): "„Å™", (1, 2, 3): "„Å´", (1, 3, 4): "„Å¨", (1, 2, 3, 4): "„Å≠", (2, 3, 4): "„ÅÆ",
        (1, 3, 6): "„ÅØ", (1, 2, 3, 6): "„Å≤", (1, 3, 4, 6): "„Åµ", (1, 2, 3, 4, 6): "„Å∏", (2, 3, 4, 6): "„Åª",
        (1, 3, 5, 6): "„Åæ", (1, 2, 3, 5, 6): "„Åø", (1, 3, 4, 5, 6): "„ÇÄ", (1, 2, 3, 4, 5, 6): "„ÇÅ", (2, 3, 4, 5, 6): "„ÇÇ",
        (3, 4): "„ÇÑ", (3, 4, 6): "„ÇÜ", (3, 4, 5): "„Çà",
        (1, 5): "„Çâ", (1, 2, 5): "„Çä", (1, 4, 5): "„Çã", (1, 2, 4, 5): "„Çå", (2, 4, 5): "„Çç",
        (3,): "„Çè", (3, 5): "„Çí", (3, 5, 6): "„Çì",
        (2,): "„Å£", (2, 5): "„Éº", (2, 5, 6): "„ÄÇ", (5, 6): "„ÄÅ", (2, 6): "Ôºü", (2, 3, 5): "ÔºÅ"
    }
    num_map = {(1,): "1", (1, 2): "2", (1, 4): "3", (1, 2, 4): "4", (1, 5): "5", (1, 6): "6", (1, 2, 5): "7", (1, 2, 6): "8", (2, 4): "9", (2, 4, 5): "0"}
    yoon_map = {
        (1,): "a", (1, 6): "„Åç„ÇÉ", (1, 4, 6): "„Åç„ÇÖ", (2, 4, 6): "„Åç„Çá",
        (1, 5, 6): "„Åó„ÇÉ", (1, 4, 5, 6): "„Åó„ÇÖ", (2, 4, 5, 6): "„Åó„Çá",
        (1, 3, 5): "„Å°„ÇÉ", (1, 3, 4, 5): "„Å°„ÇÖ", (2, 3, 4, 5): "„Å°„Çá",
        (1, 3): "„Å´„ÇÉ", (1, 3, 4): "„Å´„ÇÖ", (2, 3, 4): "„Å´„Çá",
        (1, 3, 6): "„Å≤„ÇÉ", (1, 3, 4, 6): "„Å≤„ÇÖ", (2, 3, 4, 6): "„Å≤„Çá",
        (1, 3, 5, 6): "„Åø„ÇÉ", (1, 3, 4, 5, 6): "„Åø„ÇÖ", (2, 3, 4, 5, 6): "„Åø„Çá",
        (1, 5): "„Çä„ÇÉ", (1, 4, 5): "„Çä„ÇÖ", (2, 4, 5): "„Çä„Çá",
    }
    dakuten_map = {"„Åã":"„Åå","„Åç":"„Åé","„Åè":"„Åê","„Åë":"„Åí","„Åì":"„Åî","„Åï":"„Åñ","„Åó":"„Åò","„Åô":"„Åö","„Åõ":"„Åú","„Åù":"„Åû","„Åü":"„Å†","„Å°":"„Å¢","„Å§":"„Å•","„Å¶":"„Åß","„Å®":"„Å©","„ÅØ":"„Å∞","„Å≤":"„Å≥","„Åµ":"„Å∂","„Å∏":"„Åπ","„Åª":"„Åº","„ÅÜ":"„Çî"}
    handaku_map = {"„ÅØ":"„Å±","„Å≤":"„Å¥","„Åµ":"„Å∑","„Å∏":"„Å∫","„Åª":"„ÅΩ"}

    final_text = ""
    mode_num, mode_dak, mode_han, mode_yoon = False, False, False, False
    cell_details = []

    # --- „ÄêËøΩÂä†„ÄëÁµêÊûúÁîªÂÉè‰ΩúÊàê ---
    # „Åì„Åì„ÅåÊäú„Åë„Å¶„ÅÑ„Åü„Åü„ÇÅ NameError „Å´„Å™„Å£„Å¶„ÅÑ„Åæ„Åó„Åü
    result_img = cv2.cvtColor(corrected_img, cv2.COLOR_GRAY2RGB)

    for cell in braille_cells:
        if cell.get('is_newline'): 
            final_text += "\n"
            continue
        
        rx, ry, rw, rh = map(int, cell['rect'])
        
        if cell.get('is_space'):
            final_text += "„ÄÄ"
            mode_num = False
            # Á©∫ÁôΩ„Çª„É´ÊèèÁîª (ÈªÑËâ≤)
            cv2.rectangle(result_img, (rx, ry), (rx+rw, ry+rh), (0, 255, 255), 1)
            continue
        
        # ÊñáÂ≠ó„Çª„É´ÊèèÁîª (Èùí)
        cv2.rectangle(result_img, (rx, ry), (rx+rw, ry+rh), (255, 0, 0), 2)
        
        dots = get_dots_tuple(cell['pattern'])
        char_raw = "?"
        is_special = False
        
        if dots == (3, 4, 5, 6): mode_num = True; is_special = True; char_raw="[Êï∞]"
        elif dots == (5,): mode_dak = True; is_special = True; char_raw="[ÊøÅ]"
        elif dots == (6,): mode_han = True; is_special = True; char_raw="[Âçä]"
        elif dots == (4,): mode_yoon = True; is_special = True; char_raw="[Êãó]"
        elif dots == (4, 5): mode_yoon=True; mode_dak=True; is_special=True; char_raw="[ÊãóÊøÅ]"
        elif dots == (4, 6): mode_yoon=True; mode_han=True; is_special=True; char_raw="[ÊãóÂçä]"

        if not is_special:
            if mode_num: char_raw = num_map.get(dots, "?")
            elif mode_yoon: char_raw = yoon_map.get(dots, "?"); mode_yoon = False
            else: char_raw = jp_map.get(dots, "?")
            
            if mode_dak: char_raw = dakuten_map.get(char_raw, char_raw + "„Çõ"); mode_dak = False
            elif mode_han: char_raw = handaku_map.get(char_raw, char_raw + "„Çú"); mode_han = False
            final_text += char_raw
        
        # „Éâ„ÉÉ„ÉàÁï™Âè∑ÊèèÁîª
        label = "".join(map(str, dots))
        cv2.putText(result_img, label, (rx, ry-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,200), 2)
        
        p = cell['pattern']
        vis = f"{'‚óè' if p[0] else '‚óã'} {'‚óè' if p[3] else '‚óã'}\n{'‚óè' if p[1] else '‚óã'} {'‚óè' if p[4] else '‚óã'}\n{'‚óè' if p[2] else '‚óã'} {'‚óè' if p[5] else '‚óã'}"
        cell_details.append({'char': char_raw, 'dots': dots, 'visual': vis})

    return result_img, final_text, cell_details

# ==========================================
# Streamlit UI
# ==========================================
st.title("ÁÇπÂ≠óÁøªË®≥„Ç¢„Éó„É™ (Braille Reader)")
st.write("ÁîªÂÉè„ÅÆÁÇπÂ≠óÈÉ®ÂàÜ„Çí„Éà„É™„Éü„É≥„Ç∞„Åó„Å¶ÁøªË®≥„Åó„Åæ„Åô„ÄÇ")

uploaded_file = st.file_uploader("ÁîªÂÉè„Éï„Ç°„Ç§„É´„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    try: image = ImageOps.exif_transpose(image)
    except: pass

    st.subheader("1. ÁØÑÂõ≤ÊåáÂÆö")
    cropped_img = st_cropper(image, realtime_update=True, box_color='#0000FF', aspect_ratio=None)
    
    st.subheader("2. ÁøªË®≥")
    if st.button("„Åì„ÅÆÁØÑÂõ≤„ÇíÁøªË®≥„Åô„Çã"):
        if cropped_img is not None:
            img_array = np.array(cropped_img)
            if len(img_array.shape) == 3: img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            else: img_cv = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)

            with st.spinner("Ëß£Êûê‰∏≠..."):
                result_img, text, details = process_braille_image(img_cv)
                st.success("ÂÆå‰∫ÜÔºÅ")
                
                col1, col2 = st.columns([1, 1])
                with col1:
                    st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), caption="Ëß£ÊûêÁµêÊûú", use_column_width=True)
                with col2:
                    st.text_area("ÁøªË®≥„ÉÜ„Ç≠„Çπ„Éà", text, height=200)
                
                with st.expander("Ë©≥Á¥∞„É¨„Éù„Éº„Éà„ÇíË¶ã„Çã"):
                    for i, det in enumerate(details):
                        st.text(f"[{i+1:02d}] {det['char']} {det['dots']}")
                        st.text(det['visual'])
                        st.divider()
